{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "V4aBuxpfunHB"
      },
      "outputs": [],
      "source": [
        "# November 25,2023\n",
        "# CSC461 – Assignment3 – Machine Learning\n",
        "# Hassan Mehmood\n",
        "# FA21-BSE-069\n",
        "# Apply ML Algorithms & perform the tasks given in the assignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuHIXyTiHNzL"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "#install scikitplot\n",
        "\n",
        "!pip install scikit-plot\n",
        "\n",
        "#import libraries\n",
        "\n",
        "from sklearn import preprocessing\n",
        "import pandas as pd\n",
        "\n",
        "#import different ML classifiers\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "#import ML evaluation metrics\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, LeavePOut\n",
        "from sklearn import metrics, model_selection\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "#import scikitplot to plot confusion matrix\n",
        "\n",
        "import scikitplot as skplt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-c6_Fq-jHSJo"
      },
      "outputs": [],
      "source": [
        "#import Google Drive and mount the entire drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "B8SzAqfoIEVp"
      },
      "outputs": [],
      "source": [
        "#read CSV (dataset) file\n",
        "\n",
        "gender = pd.read_csv('/content/drive/My Drive/gender-prediction.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6vPETHYW4vm",
        "outputId": "60ed3a04-8f3e-4fbd-a695-09aa793ef9c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of instances: 110\n",
            "Number of input attributes: 7\n",
            "Number of possible values for the output attribute: 2\n",
            "Number of categorical input attributes: 4\n",
            "Class ratio (male vs female): Male: 56.36% , Female: 43.64%\n"
          ]
        }
      ],
      "source": [
        "# How many instances does the dataset contain?\n",
        "\n",
        "instances = len(gender)\n",
        "print(\"Number of instances:\", instances)\n",
        "\n",
        "# How many input attributes does the dataset contain?\n",
        "\n",
        "input_attributes = len(gender.columns) - 1\n",
        "print(\"Number of input attributes:\", input_attributes)\n",
        "\n",
        "# How many possible values does the output attribute have?\n",
        "\n",
        "output_values = gender['gender'].nunique()\n",
        "print(\"Number of possible values for the output attribute:\", output_values)\n",
        "\n",
        "# How many input attributes are categorical?\n",
        "\n",
        "categorical_columns = ['beard', 'scarf', 'eye_color', 'hair_length']\n",
        "categorical_attributes = len(categorical_columns)\n",
        "print(\"Number of categorical input attributes:\", categorical_attributes)\n",
        "\n",
        "# What is the class ratio (male vs female) in the dataset?\n",
        "\n",
        "col = ['height', 'weight', 'beard', 'hair_length', 'shoe_size', 'scarf', 'eye_color', 'gender']\n",
        "df = pd.DataFrame(gender, columns=col)\n",
        "class_ratio = df['gender'].value_counts(normalize=True) * 100\n",
        "print(f\"Class ratio (male vs female): Male: {class_ratio['male']:.2f}% , Female: {class_ratio['female']:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvvpHE3uk1va",
        "outputId": "8f9a33ae-011f-4f0e-ba18-36c5c5860150"
      },
      "outputs": [],
      "source": [
        "# Separate target variable\n",
        "y = gender['gender']\n",
        "\n",
        "# Drop the target variable for encoding\n",
        "data_features = gender.drop('gender', axis=1)\n",
        "\n",
        "# convert strings values into numbers\n",
        "data_encoded = pd.get_dummies(data_features)\n",
        "\n",
        "# Prepare the features\n",
        "X = data_encoded\n",
        "\n",
        "# Splitting the data into training and testing sets (2/3 train and 1/3 test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "logistic_regression = LogisticRegression(max_iter=1000)\n",
        "svm_classifier = SVC(max_iter=1000)\n",
        "mlp_classifier = MLPClassifier(max_iter=1000)\n",
        "\n",
        "# Fit the models\n",
        "logistic_regression.fit(X_train, y_train)\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "mlp_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "logistic_regression_preds = logistic_regression.predict(X_test)\n",
        "svm_preds = svm_classifier.predict(X_test)\n",
        "mlp_preds = mlp_classifier.predict(X_test)\n",
        "\n",
        "# Incorrectly classified instances\n",
        "logistic_regression_incorrect = (y_test != logistic_regression_preds).sum()\n",
        "svm_incorrect = (y_test != svm_preds).sum()\n",
        "mlp_incorrect = (y_test != mlp_preds).sum()\n",
        "\n",
        "print(\"1. How many instances are incorrectly classified?\")\n",
        "print(\"Logistic Regression Incorrectly Classified Instances:\", logistic_regression_incorrect)\n",
        "print(\"SVM Incorrectly Classified Instances:\", svm_incorrect)\n",
        "print(\"MLP Incorrectly Classified Instances:\", mlp_incorrect)\n",
        "\n",
        "# Splitting the data into training and testing sets (2/3 train and 1/3 test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "logistic_regression = LogisticRegression(max_iter=1000)\n",
        "svm_classifier = SVC(max_iter=1000)\n",
        "mlp_classifier = MLPClassifier(max_iter=1000)\n",
        "\n",
        "# Fit the models\n",
        "logistic_regression.fit(X_train, y_train)\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "mlp_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "logistic_regression_preds = logistic_regression.predict(X_test)\n",
        "svm_preds = svm_classifier.predict(X_test)\n",
        "mlp_preds = mlp_classifier.predict(X_test)\n",
        "\n",
        "# Incorrectly classified instances\n",
        "logistic_regression_incorrect = (y_test != logistic_regression_preds).sum()\n",
        "svm_incorrect = (y_test != svm_preds).sum()\n",
        "mlp_incorrect = (y_test != mlp_preds).sum()\n",
        "\n",
        "print(\"\\n\\n2. Rerun the experiment using train/test split ratio of 80/20. Do you see any change in the results?Explain.\")\n",
        "print(\"Logistic Regression Incorrectly Classified Instances:\", logistic_regression_incorrect)\n",
        "print(\"SVM Incorrectly Classified Instances:\", svm_incorrect)\n",
        "print(\"MLP Incorrectly Classified Instances:\", mlp_incorrect)\n",
        "print(\"\\nLogistic Regression: There's no change in the number of incorrectly classified instances between the 66/33 split and 80/20 split.\\nSVM: The number of incorrectly classified instances increased from 9 in the 66/33 split to 4 in the 80/20 split.\\nMLP: The number of incorrectly classified instances changed each time for both splits.\")\n",
        "print(\" \\n Sure, changing the test split ratio from 0.33 to 0.2 alters the proportion of data used for training and testing. A 0.33 split dedicates more data for\\n training (67%) and more for testing (33%), potentially allowing for better learning and comprehensive evaluation. Conversely, a 0.2 split allocates\\n less data for testing (20%) and more for training (80%), which might lead to less comprehensive model evaluation and potentially less robust learning due\\n to a smaller training set. This change affects model performance metrics, bias-variance trade-offs,\\n and the reliability of the model's generalization to unseen data.\")\n",
        "\n",
        "print(\"\\n\\n3. Name 2 attributes that you believe are the most “powerful” in the prediction task. Explain why?\")\n",
        "feature_importance = pd.Series(logistic_regression.coef_[0], index=X.columns).sort_values(ascending=False)\n",
        "top_2_attributes = feature_importance[:2]\n",
        "print(\"Top 2 influential attributes:\")\n",
        "print(top_2_attributes)\n",
        "\n",
        "# Separate target variable\n",
        "y = gender['gender']\n",
        "\n",
        "# Drop the target variable for encoding\n",
        "data_features = gender.drop('gender', axis=1)\n",
        "data_features = data_features.drop('beard', axis=1)\n",
        "data_features = data_features.drop('hair_length', axis=1)\n",
        "\n",
        "# convert strings values into numbers\n",
        "data_encoded = pd.get_dummies(data_features)\n",
        "\n",
        "# Prepare the features\n",
        "X = data_encoded\n",
        "\n",
        "# Splitting the data into training and testing sets (2/3 train and 1/3 test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "logistic_regression = LogisticRegression(max_iter=1000)\n",
        "svm_classifier = SVC(max_iter=1000)\n",
        "mlp_classifier = MLPClassifier(max_iter=2000)\n",
        "\n",
        "# Fit the models\n",
        "logistic_regression.fit(X_train, y_train)\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "mlp_classifier.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\n\\n4. Try to exclude these 2 attribute(s) from the dataset. Rerun the experiment (using 80/20 train/test split),did you find any change in the results? Explain.\")\n",
        "feature_importance = pd.Series(logistic_regression.coef_[0], index=X.columns).sort_values(ascending=False)\n",
        "top_2_attributes = feature_importance[:2]\n",
        "print(\"Top 2 influential attributes:\")\n",
        "print(top_2_attributes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpXzrMyQApKb",
        "outputId": "961a8bbd-de43-4628-8609-6907a9df1788"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Monte Carlo F1 scores: 0.9723409605230073\n"
          ]
        }
      ],
      "source": [
        "model = RandomForestClassifier(n_estimators=50, random_state=42)  # You can modify parameters\n",
        "model.fit(X_train,y_train)\n",
        "predicted=cross_val_predict(model,X,y,cv=5)\n",
        "model_fscore = f1_score(y, predicted, average='macro')\n",
        "print(\"Monte Carlo F1 scores:\", model_fscore)\n",
        "\n",
        "# leave_p_out = LeavePOut(p=10)  # You can modify the value of 'p'\n",
        "# predicted = cross_val_predict(model, X, y, cv=leave_p_out)\n",
        "# f1 = f1_score(y, predicted, average='macro')\n",
        "# print(\"Leave P-Out F1 scores:\", f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQHo32b-nElt",
        "outputId": "fd9672b2-4dcd-4575-cbca-2c222052dabd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Consusion Matrix:\n",
            " [[4 1]\n",
            " [1 4]]\n",
            "Accuracy: 80.0%\n",
            "Precision: 0.8\n",
            "Recall: 0.8\n"
          ]
        }
      ],
      "source": [
        "new_instances = {\n",
        "    'height': [72, 67, 69, 68, 66, 64, 73, 75, 63, 70],\n",
        "    'weight': [168, 142, 150, 155, 135, 125, 180, 190, 120, 175],\n",
        "    'beard': ['yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes'],\n",
        "    'hair_length': ['short', 'bald', 'medium', 'long', 'long', 'long', 'short', 'medium', 'medium', 'medium'],\n",
        "    'shoe_size': [43, 40, 42, 38, 37, 36, 44, 45, 39, 42],\n",
        "    'scarf': ['no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no'],\n",
        "    'eye_color': ['brown', 'blue', 'brown', 'green', 'gray', 'gray', 'black', 'black', 'green', 'black'],\n",
        "    'gender': ['male', 'female', 'male', 'female', 'female', 'female', 'male', 'male', 'female', 'male']\n",
        "}\n",
        "\n",
        "df_new_instances=pd.DataFrame(new_instances)\n",
        "gender_comb=pd.concat([gender,df_new_instances])\n",
        "\n",
        "y_test_new_instances = df_new_instances['gender']\n",
        "\n",
        "# Drop the target variable for encoding\n",
        "data_features1 = df_new_instances.drop('gender', axis=1)\n",
        "\n",
        "# convert strings values into numbers\n",
        "data_encoded1 = pd.get_dummies(data_features1)\n",
        "X_test_new_instances = data_encoded1  # Features\n",
        "X_test_new_instances = X_test_new_instances.reindex(columns=X.columns, fill_value=0)\n",
        "\n",
        "model = GaussianNB()\n",
        "model.fit(X , y)\n",
        "new_predictions = model.predict(X_test_new_instances)\n",
        "\n",
        "model_cm = metrics.confusion_matrix(y_test_new_instances, new_predictions)\n",
        "print(\"Consusion Matrix:\\n\", model_cm)\n",
        "\n",
        "# Evaluate the model on the 10 new instances\n",
        "accuracy = accuracy_score(y_test_new_instances, new_predictions)*100\n",
        "precision = precision_score(y_test_new_instances, new_predictions, average='micro')\n",
        "recall = recall_score(y_test_new_instances, new_predictions, average='micro')\n",
        "\n",
        "# Print or store the accuracy, precision, and recall scores\n",
        "print(f\"Accuracy: {accuracy}%\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
